{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Shakespeare-like Text Generation with LSTM.**","metadata":{}},{"cell_type":"markdown","source":"**Importing packages.**","metadata":{}},{"cell_type":"code","source":"# numpy + ntlk toolkit.\n# Project extracted from Project Gutenberg; files: Macbeth, Complete works of Shakespeare\nimport numpy\nimport sys\nimport io\n\nfrom keras.models import Sequential\nfrom nltk.tokenize import RegexpTokenizer\nfrom nltk.corpus import stopwords\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, LSTM\nfrom keras.utils import np_utils\nfrom keras.callbacks import ModelCheckpoint\n\nprint('packages imported')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-29T17:38:13.395858Z","iopub.execute_input":"2021-11-29T17:38:13.396129Z","iopub.status.idle":"2021-11-29T17:38:13.402439Z","shell.execute_reply.started":"2021-11-29T17:38:13.396099Z","shell.execute_reply":"2021-11-29T17:38:13.401476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Tokenizer initialization.**","metadata":{}},{"cell_type":"code","source":"# read input as file\n# file = open(\"../input/macbeth/Macbeth.txt\", 'r')\n#file = io.open(\"../input/macbeth/Macbeth.txt\", mode=\"r\", encoding=\"utf-8\")\n#file.read()\n#file1 = open(\"../input/macbeth/Macbeth.txt\", mode=\"r\", encoding=\"utf-8\")\n#file2 = [line.rstrip('\\n') for line in file1]\n#file3 = [open(file1).read() for file1 in text_files]\n\nwith open(\"../input/macbeth/Macbeth.txt\", mode=\"r\", encoding=\"utf-8\") as file4:\n          file = file4.read()\n          #print(file)\n\ndef tokenize_words(input):\n    # lowercase text.\n    input = input.lower()\n\n    # Tokenizer\n    tokenizer = RegexpTokenizer(r'\\w+')\n    tokens = tokenizer.tokenize(input)\n\n    # Filtered text only.\n    filtered = filter(lambda token: token not in stopwords.words('english'), tokens)\n    return \" \".join(filtered)\n\nprocessed_inputs = tokenize_words(file)\nchars = sorted(list(set(processed_inputs)))\nchar_to_num = dict((c, i) for i, c in enumerate(chars))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-29T17:38:16.100738Z","iopub.execute_input":"2021-11-29T17:38:16.101133Z","iopub.status.idle":"2021-11-29T17:38:18.511345Z","shell.execute_reply.started":"2021-11-29T17:38:16.101095Z","shell.execute_reply":"2021-11-29T17:38:18.510612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Vocab stats**","metadata":{}},{"cell_type":"code","source":"input_len = len(processed_inputs)\nvocab_len = len(chars)\nprint (\"Total number of characters:\", input_len)\nprint (\"Total vocab:\", vocab_len)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T17:40:39.922652Z","iopub.execute_input":"2021-11-29T17:40:39.923042Z","iopub.status.idle":"2021-11-29T17:40:39.928589Z","shell.execute_reply.started":"2021-11-29T17:40:39.923Z","shell.execute_reply":"2021-11-29T17:40:39.927861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Sequence Length**","metadata":{}},{"cell_type":"code","source":"seq_length = 100\nx_data = []\ny_data = []","metadata":{"execution":{"iopub.status.busy":"2021-11-29T17:41:33.619849Z","iopub.execute_input":"2021-11-29T17:41:33.620622Z","iopub.status.idle":"2021-11-29T17:41:33.624571Z","shell.execute_reply.started":"2021-11-29T17:41:33.620582Z","shell.execute_reply":"2021-11-29T17:41:33.623605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# loop through inputs, start at the beginning and go until we hit\n# the final character we can create a sequence out of\nfor i in range(0, input_len - seq_length, 1):\n    # Define input and output sequences\n    # Input is the current character plus desired sequence length\n    in_seq = processed_inputs[i:i + seq_length]\n\n    # Out sequence is the initial character plus total sequence length\n    out_seq = processed_inputs[i + seq_length]\n\n    # We now convert list of characters to integers based on\n    # previously and add the values to our lists\n    x_data.append([char_to_num[char] for char in in_seq])\n    y_data.append(char_to_num[out_seq])","metadata":{"execution":{"iopub.status.busy":"2021-11-29T17:44:31.392119Z","iopub.execute_input":"2021-11-29T17:44:31.392692Z","iopub.status.idle":"2021-11-29T17:44:31.958487Z","shell.execute_reply.started":"2021-11-29T17:44:31.392653Z","shell.execute_reply":"2021-11-29T17:44:31.957715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Total patterns**","metadata":{}},{"cell_type":"code","source":"n_patterns = len(x_data)\nprint (\"Total Patterns:\", n_patterns)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T17:49:36.240168Z","iopub.execute_input":"2021-11-29T17:49:36.240451Z","iopub.status.idle":"2021-11-29T17:49:36.24559Z","shell.execute_reply.started":"2021-11-29T17:49:36.240422Z","shell.execute_reply":"2021-11-29T17:49:36.24489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = numpy.reshape(x_data, (n_patterns, seq_length, 1))\nX = X/float(vocab_len)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T17:49:53.897675Z","iopub.execute_input":"2021-11-29T17:49:53.897926Z","iopub.status.idle":"2021-11-29T17:49:55.291321Z","shell.execute_reply.started":"2021-11-29T17:49:53.897895Z","shell.execute_reply":"2021-11-29T17:49:55.29057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = np_utils.to_categorical(y_data)","metadata":{"execution":{"iopub.status.busy":"2021-11-29T17:49:58.89787Z","iopub.execute_input":"2021-11-29T17:49:58.898439Z","iopub.status.idle":"2021-11-29T17:49:58.927405Z","shell.execute_reply.started":"2021-11-29T17:49:58.898397Z","shell.execute_reply":"2021-11-29T17:49:58.92667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(256, return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(LSTM(128))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(y.shape[1], activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2021-11-29T17:37:27.306971Z","iopub.execute_input":"2021-11-29T17:37:27.307259Z","iopub.status.idle":"2021-11-29T17:37:30.3829Z","shell.execute_reply.started":"2021-11-29T17:37:27.307227Z","shell.execute_reply":"2021-11-29T17:37:30.382026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='categorical_crossentropy', optimizer='adam')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filepath = \"model_weights_saved.hdf5\"\ncheckpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\ndesired_callbacks = [checkpoint]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(X, y, epochs=4, batch_size=256, callbacks=desired_callbacks)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filename = \"model_weights_saved.hdf5\"\nmodel.load_weights(filename)\nmodel.compile(loss='categorical_crossentropy', optimizer='adam')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_to_char = dict((i, c) for i, c in enumerate(chars))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start = numpy.random.randint(0, len(x_data) - 1)\npattern = x_data[start]\nprint(\"Random Seed:\")\nprint(\"\\\"\", ''.join([num_to_char[value] for value in pattern]), \"\\\"\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(1000):\n    x = numpy.reshape(pattern, (1, len(pattern), 1))\n    x = x / float(vocab_len)\n    prediction = model.predict(x, verbose=0)\n    index = numpy.argmax(prediction)\n    result = num_to_char[index]\n\n    sys.stdout.write(result)\n\n    pattern.append(index)\n    pattern = pattern[1:len(pattern)]","metadata":{},"execution_count":null,"outputs":[]}]}